import os, torch, soundfile as sf
from Net import UNetBiGRU
from torchmetrics.audio.pesq import PerceptualEvaluationSpeechQuality
from torchmetrics.audio.stoi import ShortTimeObjectiveIntelligibility

SR, N_FFT, HOP = 16000, 512, 256
WIN = torch.hann_window(N_FFT)
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

CKPT = "model.pth"
NOISY = "data/noisy.wav"
CLEAN = "data/clean.wav"
OUT   = "out/enhanced.wav"
os.makedirs(os.path.dirname(OUT), exist_ok=True)
@torch.no_grad()
def sisnr(x, s, eps=1e-8):
    s_zm, x_zm = s - s.mean(-1, True), x - x.mean(-1, True)
    proj = (torch.sum(x_zm*s_zm, -1, True) / (torch.sum(s_zm**2, -1, True) + eps)) * s_zm
    e = x_zm - proj
    return 10 * torch.log10((torch.sum(proj**2, -1) + eps) / (torch.sum(e**2, -1) + eps))
@torch.no_grad()
def sdr(x, s, eps=1e-8):
    return 10 * torch.log10((torch.sum(s**2, -1) + eps) / (torch.sum((s - x)**2, -1) + eps))

if __name__ == "__main__":
    model = UNetBiGRU(base=16).to(DEVICE)
    state = torch.load(CKPT, map_location=DEVICE)
    model.load_state_dict(state["model"] if isinstance(state, dict) and "model" in state else state, strict=True)
    model.eval()
    noisy, sr_n = sf.read(NOISY, dtype="float32");  noisy = noisy[:,0] if noisy.ndim==2 else noisy
    clean, sr_c = sf.read(CLEAN, dtype="float32");  clean = clean[:,0] if clean.ndim==2 else clean
    L = max(len(noisy), len(clean))
    Lp = L if L % HOP == 0 else L + (HOP - L % HOP)
    import numpy as np
    if len(noisy) < Lp: noisy = np.pad(noisy, (0, Lp - len(noisy)))
    if len(clean) < Lp: clean = np.pad(clean, (0, Lp - len(clean)))
    noisy_t = torch.from_numpy(noisy).unsqueeze(0).to(DEVICE)
    clean_t = torch.from_numpy(clean).unsqueeze(0).to(DEVICE)
    S = torch.stft(noisy_t, n_fft=N_FFT, hop_length=HOP, win_length=N_FFT, window=WIN.to(DEVICE), return_complex=True, center=True)
    Sr, Si, Sm = S.real, S.imag, torch.abs(S)
    feats = torch.stack([Sr.permute(0,2,1), Si.permute(0,2,1), Sm.permute(0,2,1)], dim=1)
    n_params = sum(p.numel() for p in model.parameters())
    print(f"[Model] params={n_params}")
    with torch.no_grad():
        M = model(feats)
        Mr = M[:,0].permute(0,2,1)
        Mi = M[:,1].permute(0,2,1)
        S_hat = torch.complex(Mr, Mi) * S
    est = torch.istft(S_hat, n_fft=N_FFT, hop_length=HOP, win_length=N_FFT, window=WIN.to(DEVICE), length=noisy_t.shape[-1], center=True)[0, :L]
    sf.write(OUT, est.detach().cpu().to(torch.float32).numpy(), SR)
    print(f"[Saved] {OUT}")
    esti = est.unsqueeze(0)
    clni = clean_t[0, :L].unsqueeze(0)
    pesq_metric = PerceptualEvaluationSpeechQuality(SR, mode="wb").to(DEVICE)
    stoi_metric = ShortTimeObjectiveIntelligibility(SR, extended=False).to(DEVICE)
    pesq = pesq_metric(esti, clni).item()
    stoi = stoi_metric(esti, clni).item()
    si   = sisnr(esti, clni).item()
    sd   = sdr(esti, clni).item()
    print(f"[Metrics] PESQ={pesq:.3f}, STOI={stoi:.3f}, SiSNR={si:.2f} dB, SDR={sd:.2f} dB")
